---
title: "Regression in R"
output: pdf_document
---



# load useful packages for formatting output

```{r, warnings=F}

library( pander ) # translate output to HTML / latex

library(  magrittr )  # use the pipe operator %>%

library( knitr )  # kable function formats tables

```



# create some fake data

```{r}

x1 <- 1:100

x2 <- -0.1*x1 + rnorm(100)

x3 <- 0.05*x2 + rnorm(100)

y <- 2*x1 + 10*rnorm(100) + 10*x2

dat <- data.frame( y, x1, x2, x3 )

head( dat )

```


\newpage


# descriptive statistics

```{r}

summary( dat ) %>% kable

library( pastecs ) # convenient descriptives function

stat.desc( dat ) %>% t %>% pander

#print( t( stat.desc( dat ) ), digits=3 )

# To copy and paste into Excel:
#
# descriptives <- t( stat.desc(dat) )
# 
# write.table( descriptives, "clipboard", sep="\t", row.names=TRUE )

```


```{r, warning=F}

# To create nicely formatted tables for markdown documents use the kable() function

library( knitr )

kable( t( stat.desc( dat )[ c(1,4,5,8,9,13), ] ), format="markdown", digits=3 )

```






```{r}
t( stat.desc( dat )[ c(1,4,5,8,9,13), ] ) %>% pander
```





\newpage



# pretty pairs plot

Convenient visual descriptives:

```{r}

pairs( dat )
```

We can improve it:

```{r}

panel.cor <- function(x, y, digits=2, prefix="", cex.cor)
{
    usr <- par("usr"); on.exit(par(usr))
    par(usr = c(0, 1, 0, 1))
    r <- abs(cor(x, y))
    txt <- format(c(r, 0.123456789), digits=digits)[1]
    txt <- paste(prefix, txt, sep="")
    if(missing(cex.cor)) cex <- 0.8/strwidth(txt)
    
    test <- cor.test(x,y)
    # borrowed from printCoefmat
    Signif <- symnum(test$p.value, corr = FALSE, na = FALSE,
                  cutpoints = c(0, 0.001, 0.01, 0.05, 0.1, 1),
                  symbols = c("***", "**", "*", ".", " "))
    
    text(0.5, 0.5, txt, cex = 1.5 )
    text(.7, .8, Signif, cex=cex, col=2)
}


pairs( dat, lower.panel=panel.smooth, upper.panel=panel.cor)

```






# create some fake regression data

```{r}

x <- 1:100
y <- 2*x + rnorm(100,0,20)

plot( x, y )

dum <- sample( c("NJ","NY","MA","PA"), 100, replace=T )

```






# basic regression syntax

The regression is run using the "linear model" command. The basic model will print the minimum output:

```{r}


lm( y ~ x )


```


To generate nicely-formatted regression tables save the results from the regression as an object, and format the output for inclusion in a markdown document using the `pander` package.

```{r}

m.01 <- lm( y ~ x )

summary( m.01 ) %>% pander  # add pander to format for markdown docs

```



# nice visual diagnostics of model fit

```{r}
par( mfrow=c(2,2) )
plot( m.01 )
```




# useful model fit functions

```{r, warning=F }

coefficients( m.01 ) %>% pander # model coefficients

confint( m.01, level=0.95) %>% pander # CIs for model parameters 

# not run because of long output

# anova( m.01 ) # anova table 
# fitted( m.01 ) # predicted values
# residuals( m.01 ) # residuals
# influence( m.01 ) # regression diagnostics


```



```{r, warning=F }

library( coefplot )

m.02 <-  lm( y ~ x1 + I(x1^2) + x2 + x3 )

coefplot(m.02)

```




# pretty output

```{r, warning=FALSE }

# install.packages( "memisc" )

library( memisc )

x_sqr <- x * x

m.01 <- lm( y ~ x )
m.02 <- lm( y ~ x + x_sqr )  # quadratic term
m.03 <- lm( y ~ x - 1 )       # no intercept term


pretty.table <- mtable("Model 1"=m.01,"Model 2"=m.02,"Model 3"=m.03,
                  summary.stats=c("R-squared","F","p","N"))

pretty.table %>% pander

```














# specification

```{r}

summary( lm( y ~ x1 + x2 + x3 ) ) %>% pander

# add different functional forms

# square x1

summary( lm( y ~ x1 + x1^2 + x2 + x3 ) )  %>% pander      # incorrect

summary( lm( y ~ x1 + I(x1^2) + x2 + x3 ) )  %>% pander   # correct - enclose with I()

summary( lm( y ~ log(x1) + x2 + x3 ) )   %>% pander       # log of x1 in formula works fine


```

```{r}
# interactions

summary( lm( y ~ x1 + x2 ) ) %>% pander

summary( lm( y ~ x1 + x2 + I(x1*x2) ) )  %>% pander

summary( lm( y ~ x1*x2 ) ) %>% pander    # shortcut
```

```{r}
# dummy variables

summary( lm( y ~ x1 + x2 + x3 + dum ) ) %>% pander     # drop one level

summary( lm( y ~ x1 + x2 + x3 + dum - 1) ) %>% pander  # keep all, drop intercept
```












# standardized regression coefficients (beta)



```{r, warning=F }
# install.packages( "lm.beta" )

library( lm.beta )

m.01.beta <- lm.beta( m.01 )

summary( m.01.beta ) %>% pander

# coef( m.01.beta )


```

```{r}
# note the standard error is not standardized - describes regular coefficients

summary( m.01 ) %>% pander
```





# or just use the formula:
```{r}
lm.beta <- function( my.mod ) 
{
    b <- summary(my.mod)$coef[-1, 1]
    sx <- sd( my.mod$model[,-1] )
    sy <- sd( my.mod$model[,1] )
    beta <- b * sx/sy
    return(beta)
}


coefficients( m.01 ) %>% pander

lm.beta( m.01 ) %>% pander
```












# robust standard errors


```{r, warning=FALSE}

# install.packages( "sandwhich" )
# install.packages( "lmtest" )

library(sandwich)
library(lmtest)

m.01 <- lm( y ~ x )


# REGULAR STANDARD ERRORS - not robust

summary( m.01 ) %>% pander





```

```{r}
# ROBUST STANDARD ERRORS

# reproduce the Stata default
coeftest( m.01, vcov=vcovHC(m.01,"HC1") )    # robust; HC1 (Stata default)
```



```{r}
# ROBUST STANDARD ERRORS

# check that "sandwich" returns HC0
coeftest(m.01, vcov = sandwich)                # robust; sandwich
coeftest(m.01, vcov = vcovHC(m.01, "HC0"))     # robust; HC0 
```


```{r}
# ROBUST STANDARD ERRORS

# check that the default robust var-cov matrix is HC3
coeftest(m.01, vcov = vcovHC(m.01))            # robust; HC3 
coeftest(m.01, vcov = vcovHC(m.01, "HC3"))     # robust; HC3 (default)
```

