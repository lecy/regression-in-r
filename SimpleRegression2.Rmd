---
title: "Regression in R"
output: html_notebook
---




# create some fake data

```{r}

x1 <- 1:100

x2 <- -0.1*x1 + rnorm(100)

x3 <- 0.05*x2 + rnorm(100)

y <- 2*x1 + 10*rnorm(100) + 10*x2

dat <- data.frame( y, x1, x2, x3 )

```


# descriptive statistics

```{r}

library( pastecs )

print( t( stat.desc( dat ) ), digits=3 )

# To copy and paste into Excel:
#
# descriptives <- t( stat.desc(dat) )
# 
# write.table( descriptives, "clipboard", sep="\t", row.names=TRUE )

```


```{r}
library( knitr )

kable( t( stat.desc( dat )[ c(1,4,5,8,9,13), ] ))

```



|   | nbr.val|       min|        max|     median|       mean|   std.dev|
|:--|-------:|---------:|----------:|----------:|----------:|---------:|
|y  |     100| -11.21009| 118.496663| 50.5912313| 52.3953240| 31.342384|
|x1 |     100|   1.00000| 100.000000| 50.5000000| 50.5000000| 29.011492|
|x2 |     100| -10.85073|   1.070874| -5.0970318| -4.9638570|  3.135171|
|x3 |     100|  -2.54842|   1.857019| -0.4090529| -0.3804099|  1.060447|



```{r}
pairs( dat )
```









# pretty pairs plot

```{r}

panel.cor <- function(x, y, digits=2, prefix="", cex.cor)
{
    usr <- par("usr"); on.exit(par(usr))
    par(usr = c(0, 1, 0, 1))
    r <- abs(cor(x, y))
    txt <- format(c(r, 0.123456789), digits=digits)[1]
    txt <- paste(prefix, txt, sep="")
    if(missing(cex.cor)) cex <- 0.8/strwidth(txt)
    
    test <- cor.test(x,y)
    # borrowed from printCoefmat
    Signif <- symnum(test$p.value, corr = FALSE, na = FALSE,
                  cutpoints = c(0, 0.001, 0.01, 0.05, 0.1, 1),
                  symbols = c("***", "**", "*", ".", " "))
    
    text(0.5, 0.5, txt, cex = 1.5 )
    text(.7, .8, Signif, cex=cex, col=2)
}


pairs( dat, lower.panel=panel.smooth, upper.panel=panel.cor)

```






# create some fake regression data

```{r}

x <- 1:100
y <- 2*x + rnorm(100,0,20)

plot( x, y )

dum <- sample( c("NJ","NY","MA","PA"), 100, replace=T )


```






# basic regression syntax

```{r}
lm( y ~ x )

m.01 <- lm( y ~ x )

summary( m.01 )
```




# nice visual diagnostics

```{r}
par( mfrow=c(2,2) )
plot( m.01 )
```




# useful model fit functions

```{r}


coefficients( m.01 ) # model coefficients
confint( m.01, level=0.95) # CIs for model parameters 
head( fitted( m.01 )) # predicted values
residuals( m.01 ) # residuals
anova( m.01 ) # anova table 
influence( m.01 ) # regression diagnostics


```





# pretty output

```{r}

# install.packages( "memisc" )

library( memisc )

m.02 <- lm( y ~ x + I(x^2) )  # quadratic term
m.03 <- lm( y ~ x - 1 )       # no intercept term


pretty.table <- mtable("Model 1"=m.01,"Model 2"=m.02,"Model 3"=m.03,
                  summary.stats=c("R-squared","F","p","N"))

pretty.table

```














# specification

```{r}

summary( lm( y ~ x1 + x2 + x3 ) )

# add different functional forms

summary( lm( y ~ x1^2 + x2 + x3 ) )  # not right

summary( lm( y ~ I(x1^2) + x2 + x3 ) )  # like this

summary( lm( y ~ log(x1) + x2 + x3 ) )


# interactions

summary( lm( y ~ x1 + x2 ) )

summary( lm( y ~ x1 + x2 + I(x1*x2) ) )

summary( lm( y ~ x1*x2 ) ) # shortcut


# dummy variables

summary( lm( y ~ x1 + x2 + x3 + dum ) ) # drop one level

summary( lm( y ~ x1 + x2 + x3 + dum - 1) ) # keep all, drop intercept

```












# standardized regression coefficients (beta)



```{r}
# install.packages( "lm.beta" )

coefficients( m.01 )

library( lm.beta )

m.01.beta <- lm.beta( m.01 )
print( m.01.beta )
summary( m.01.beta )
coef( m.01.beta )

# note the standard error is for the normal slope coefficients

summary( m.01 )
```





# or just use the formula:
```{r}
lm.beta <- function( my.mod ) 
{
    b <- summary(my.mod)$coef[-1, 1]
    sx <- sd( my.mod$model[,-1] )
    sy <- sd( my.mod$model[,1] )
    beta <- b * sx/sy
    return(beta)
}


coefficients( m.01 )

lm.beta( m.01 )
```












# robust standard errors


```{r}

# install.packages( "sandwhich" )
# install.packages( "lmtest" )

library(sandwich)
library(lmtest)

m.01 <- lm( y ~ x )

summary( m.01 )                                # non-robust



# reproduce the Stata default
coeftest( m.01, vcov=vcovHC(m.01,"HC1") )      # robust; HC1 (Stata default)

# check that "sandwich" returns HC0
coeftest(m.01, vcov = sandwich)                # robust; sandwich
coeftest(m.01, vcov = vcovHC(m.01, "HC0"))     # robust; HC0 

# check that the default robust var-cov matrix is HC3
coeftest(m.01, vcov = vcovHC(m.01))            # robust; HC3 
coeftest(m.01, vcov = vcovHC(m.01, "HC3"))     # robust; HC3 (default)


```



